整个运行流程的总结
加载数据：将原始文本数据处理为模型可接受的格式。
构建模型：加载预训练 BERT 模型，并添加分类层。
训练模型：通过反复优化模型参数，让模型学习数据特征。
保存模型：选择验证集上表现最好的模型进行保存。
测试模型：加载最佳模型，在测试集上评估最终性能。
输出结果：显示训练和测试的所有重要信息。


1. 配置和初始化
导入依赖库：加载用于数据处理、深度学习、BERT模型和评估的各种库。

定义配置类 (Config)：

设置数据路径（训练集、验证集、测试集）。
定义超参数（学习率、批次大小、句子长度、类别数等）。
加载预训练的 BERT 模型路径和分词器。
随机种子设置：固定随机种子，确保代码多次运行结果一致。


2. 数据预处理
加载数据集：

读取训练集、验证集、测试集的数据文件。
每行数据按照 文本\t标签 格式被拆分。
使用 BERT 分词器将文本分词，并转化为对应的 ID。
对序列进行长度规范化（短填长切），并生成 mask 掩码。
构建迭代器：

将预处理后的数据封装为 DatasetIterator，用于批量加载数据


3. 模型定义
加载预训练模型：

使用 BertModel.from_pretrained 加载 BERT 模型，作为基础的特征提取器。
设置 BERT 模型的参数为可训练状态。
添加分类层：

在 BERT 输出的特征基础上，增加一个全连接层（self.fc），将特征映射到分类结果（类别数）


4. 模型训练
训练准备：

定义优化器（AdamW）和学习率调度器（get_linear_schedule_with_warmup）。
初始化模型状态变量，比如累计的训练步数、最佳验证损失等。
训练循环：

遍历每个 epoch（训练轮数）：
按批次从训练集迭代器中加载数据。
将数据输入模型，计算预测结果。
计算损失（交叉熵），并反向传播以更新模型参数。
定期在验证集上评估模型性能，记录验证损失和准确率。
如果验证效果长时间没有提升（早停条件），提前结束训练。
模型保存：

如果验证集的损失降低（性能提升），保存当前模型的参数到指定文件。


5. 模型测试
加载最佳模型：

训练完成后，加载在验证集上表现最好的模型参数。
测试评估：

使用测试集数据，评估模型的最终性能。
计算并输出：
测试损失和准确率。
分类报告（每类的精确率、召回率、F1分数）。
混淆矩阵（显示预测结果和真实结果的对应关系）。



6. 输出结果
输出整个训练和测试的日志，包括每个阶段的时间消耗、模型参数、损失和准确率等。
打印分类报告和混淆矩阵。
